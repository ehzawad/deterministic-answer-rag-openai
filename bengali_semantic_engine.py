#!/usr/bin/env python3
"""
ЁЯЗзЁЯЗй Advanced Bengali Semantic Engine
Deep linguistic understanding for nuanced Bengali banking queries
Handles morphology, syntax, cultural context, and semantic equivalences
"""

import re
import json
import logging
from typing import Dict, List, Tuple, Optional, Set
from dataclasses import dataclass
from enum import Enum

logger = logging.getLogger(__name__)

@dataclass
class BengaliMorpheme:
    """Bengali morpheme with grammatical information"""
    root: str
    prefix: str = ""
    suffix: str = ""
    pos_tag: str = ""  # Part of speech
    semantic_class: str = ""

@dataclass
class SemanticMapping:
    """Advanced semantic mapping for Bengali terms"""
    source_terms: List[str]
    target_terms: List[str]
    confidence: float
    context: str
    morphological_variants: List[str]

class BengaliSemanticEngine:
    """ЁЯза Advanced Bengali semantic understanding engine"""
    
    def __init__(self):
        self.morphological_rules = self._load_morphological_rules()
        self.semantic_mappings = self._load_semantic_mappings()
        self.banking_ontology = self._load_banking_ontology()
        self.cultural_context = self._load_cultural_context()
        self.phonetic_variants = self._load_phonetic_variants()
        
    def _load_morphological_rules(self) -> Dict:
        """ЁЯФд Load Bengali morphological analysis rules"""
        return {
            'possessive_markers': ['ржПрж░', 'рж░', 'ржХрзЗ', 'рждрзЗ', 'ржерзЗржХрзЗ'],
            'verb_inflections': ['рждрзЗ ржкрж╛рж░рж┐', 'рждрзЗ рж╣ржмрзЗ', 'рждрзЗ ржЪрж╛ржЗ', 'ржХрж░рждрзЗ', 'ржЦрзБрж▓рждрзЗ', 'ржкрзЗрждрзЗ'],
            'question_words': ['ржХрж┐', 'ржХрзА', 'ржХржд', 'ржХрзЗржоржи', 'ржХрзЛржи', 'ржХрж╛рж░', 'ржХрзЗржи', 'ржХрж┐ржнрж╛ржмрзЗ'],
            'respect_markers': ['ржЧрзБрж▓рзЛ', 'ржЧрзБрж▓рж┐', 'рж╕ржорзВрж╣', 'ржжрзЗрж░']
        }
    
    def _load_semantic_mappings(self) -> Dict:
        """ЁЯОп Advanced semantic mappings for Bengali banking"""
        return {
            # Account variations with morphological awareness
            'account_terms': {
                'patterns': [
                    {'input': r'(ржПржХрж╛ржЙржирзНржЯ|ржЕрзНржпрж╛ржХрж╛ржЙржирзНржЯ|рж╣рж┐рж╕рж╛ржм|ржЦрж╛рждрж╛)(ржПрж░|рж░|рзЗ)?', 'output': 'ржПржХрж╛ржЙржирзНржЯ'},
                    {'input': r'(ржмрзЗрждржирзЗрж░|ржкрзЗрж░рзЛрж▓|рж╕рзНржпрж╛рж▓рж╛рж░рж┐)(.*)(ржПржХрж╛ржЙржирзНржЯ|ржЕрзНржпрж╛ржХрж╛ржЙржирзНржЯ)', 'output': 'ржкрзЗрж░рзЛрж▓ ржПржХрж╛ржЙржирзНржЯ'},
                    {'input': r'(ржПржоржЯрж┐ржмрж┐|MTB).*(рж░рзЗржЧрзБрж▓рж╛рж░|regular)', 'output': 'ржПржоржЯрж┐ржмрж┐ ржПржиржЖрж░ржмрж┐'},
                    {'input': r'(ржПрж╕ржПржоржЗ|SME).*(ржПржХрж╛ржЙржирзНржЯ|ржЕрзНржпрж╛ржХрж╛ржЙржирзНржЯ)', 'output': 'ржПрж╕ржПржоржЗ ржПржХрж╛ржЙржирзНржЯ'},
                    {'input': r'(ржорж╣рж┐рж▓рж╛|ржирж╛рж░рзА|ржЕржЩрзНржЧржирж╛).*(ржПржХрж╛ржЙржирзНржЯ|ржЕрзНржпрж╛ржХрж╛ржЙржирзНржЯ)', 'output': 'ржЕржЩрзНржЧржирж╛ ржПржХрж╛ржЙржирзНржЯ'}
                ]
            },
            
            # Interest/Profit with Islamic context awareness
            'interest_terms': {
                'patterns': [
                    {'input': r'(рж╕рзБржж|рж╕рзБржжрзЗрж░ рж╣рж╛рж░)', 'output': 'ржЗржирзНржЯрж╛рж░рзЗрж╕рзНржЯ рж░рзЗржЯ', 'context': 'conventional'},
                    {'input': r'(ржЗржирзНржЯрж╛рж░рзЗрж╕рзНржЯ|ржЗржирзНржЯрж╛рж░рж╕рзЗржЯ).*(рж░рзЗржЯ|рж╣рж╛рж░)', 'output': 'ржЗржирзНржЯрж╛рж░рзЗрж╕рзНржЯ рж░рзЗржЯ'},
                    {'input': r'(ржкрзНрж░ржлрж┐ржЯ|рж▓рж╛ржн).*(рж░рзЗржЯ|рж╣рж╛рж░)', 'output': 'ржкрзНрж░ржлрж┐ржЯ рж░рзЗржЯ', 'context': 'islamic'},
                    {'input': r'(ржЗржпрж╝рж╛ржХрж┐ржи|yaqeen).*(рж░рзЗржЯ|рж╣рж╛рж░)', 'output': 'ржкрзНрж░ржлрж┐ржЯ рж░рзЗржЯ', 'context': 'islamic'}
                ]
            },
            
            # Charges and fees with contextual mapping
            'charge_terms': {
                'patterns': [
                    {'input': r'(ржЪрж╛рж░рзНржЬ|ржлрж┐|ржЦрж░ржЪ|ржмрзНржпржпрж╝)', 'output': 'ржЪрж╛рж░рзНржЬ'},
                    {'input': r'(ржмрж╛рзОрж╕рж░рж┐ржХ|ржмрж╛рж░рзНрж╖рж┐ржХ|yearly).*(ржЪрж╛рж░рзНржЬ|ржлрж┐)', 'output': 'ржмрж╛рж░рзНрж╖рж┐ржХ ржЪрж╛рж░рзНржЬ'},
                    {'input': r'(ржорж╛рж╕рж┐ржХ|monthly).*(ржЪрж╛рж░рзНржЬ|ржлрж┐)', 'output': 'ржорж╛рж╕рж┐ржХ ржЪрж╛рж░рзНржЬ'},
                    {'input': r'(ржХрж╛рж░рзНржб|card).*(ржЪрж╛рж░рзНржЬ|ржлрж┐)', 'output': 'ржХрж╛рж░рзНржб ржЪрж╛рж░рзНржЬ'}
                ]
            },
            
            # Benefits with comprehensive coverage
            'benefit_terms': {
                'patterns': [
                    {'input': r'(рж╕рзБржмрж┐ржзрж╛|рж╕рзБржмрж┐ржзрж╛рж╕ржорзВрж╣|ржмрзЗржирж┐ржлрж┐ржЯ)', 'output': 'рж╕рзБржмрж┐ржзрж╛'},
                    {'input': r'(ржХрж┐|ржХрзА).*(рж╕рзБржмрж┐ржзрж╛)', 'output': 'ржХрж┐ рж╕рзБржмрж┐ржзрж╛'},
                    {'input': r'(рж╕рзБржмрж┐ржзрж╛).*(ржХрж┐|ржХрзА)', 'output': 'рж╕рзБржмрж┐ржзрж╛ ржХрж┐'},
                    {'input': r'(ржлрж╛ржпрж╝ржжрж╛|рж▓рж╛ржн|advantage)', 'output': 'рж╕рзБржмрж┐ржзрж╛'}
                ]
            }
        }
    
    def _load_banking_ontology(self) -> Dict:
        """ЁЯПж Load comprehensive Bengali banking domain ontology"""
        return {
            'account_types': {
                'рж╕ржЮрзНржЪржпрж╝': 'savings',
                'ржЪрж▓рждрж┐': 'current', 
                'ржЬржорж╛': 'deposit',
                'ржорзЗржпрж╝рж╛ржжрзА': 'fixed_deposit',
                'ржкрзЗрж░рзЛрж▓': 'payroll',
                'ржПрж╕ржПржоржЗ': 'sme',
                'ржХрж░рзНржкрзЛрж░рзЗржЯ': 'corporate',
                'ржЕржЩрзНржЧржирж╛': 'women_banking',
                'ржЗржпрж╝рж╛ржХрж┐ржи': 'islamic_banking',
                'ржкрзНрж░рж┐ржнрж┐рж▓рзЗржЬ': 'privilege'
            },
            
            'banking_actions': {
                'ржЦрзЛрж▓рж╛': 'open',
                'ржЦрзБрж▓рждрзЗ': 'to_open', 
                'ржмржирзНржз': 'close',
                'ржЬржорж╛': 'deposit',
                'рждрзЛрж▓рж╛': 'withdraw',
                'рж╕рзНржерж╛ржирж╛ржирзНрждрж░': 'transfer',
                'ржкрж╛ржарж╛ржирзЛ': 'send',
                'ржЖржирж╛': 'bring',
                'рж░рж╛ржЦрж╛': 'keep'
            },
            
            'financial_terms': {
                'ржЯрж╛ржХрж╛': 'money',
                'ржкржпрж╝рж╕рж╛': 'money',
                'ржЕрж░рзНрже': 'money',
                'ржмрзНржпрж╛рж▓рзЗржирзНрж╕': 'balance',
                'ржЬржорж╛рж░ ржкрж░рж┐ржорж╛ржг': 'deposit_amount',
                'ржорж┐ржирж┐ржорж╛ржо': 'minimum',
                'рж╕рж░рзНржмрзЛржЪрзНржЪ': 'maximum',
                'рж▓рж┐ржорж┐ржЯ': 'limit',
                'рж╕рзАржорж╛': 'limit'
            },
            
            'time_expressions': {
                'ржжрзИржирж┐ржХ': 'daily',
                'рж╕рж╛ржкрзНрждрж╛рж╣рж┐ржХ': 'weekly', 
                'ржорж╛рж╕рж┐ржХ': 'monthly',
                'ржмрж╛рзОрж╕рж░рж┐ржХ': 'yearly',
                'ржмрж╛рж░рзНрж╖рж┐ржХ': 'annual',
                'рждрж╛рзОржХрзНрж╖ржгрж┐ржХ': 'instant',
                'ржЕржмрж┐рж▓ржорзНржмрзЗ': 'immediate'
            }
        }
    
    def _load_cultural_context(self) -> Dict:
        """ЁЯМЯ Bengali cultural and banking context"""
        return {
            'islamic_indicators': ['ржЗржпрж╝рж╛ржХрж┐ржи', 'ржЗрж╕рж▓рж╛ржорж┐ржХ', 'рж╢рж░рж┐ржпрж╝рж╛', 'рж╣рж╛рж▓рж╛рж▓', 'ржкрзНрж░ржлрж┐ржЯ'],
            'conventional_indicators': ['ржПржоржЯрж┐ржмрж┐', 'рж░рзЗржЧрзБрж▓рж╛рж░', 'рж╕рж╛ржзрж╛рж░ржг', 'рж╕рзБржж'],
            'business_context': ['ржПрж╕ржПржоржЗ', 'ржмрзНржпржмрж╕рж╛', 'ржмрзНржпржмрж╕рж╛ржпрж╝рзА', 'ржХрзЛржорзНржкрж╛ржирж┐', 'ржлрж╛рж░рзНржо'],
            'personal_context': ['ржмрзНржпржХрзНрждрж┐ржЧржд', 'ржкрж╛рж░рж┐ржмрж╛рж░рж┐ржХ', 'ржирж┐ржЬрзЗрж░'],
            'formality_markers': ['ржЖржкржирж┐', 'ржЖржкржирж╛рж░', 'ржЖржкржирж╛ржжрзЗрж░'],
            'question_intentions': {
                'information_seeking': ['ржЬрж╛ржирждрзЗ ржЪрж╛ржЗ', 'ржмрж▓рзБржи', 'ржмрж▓рзЗржи'],
                'decision_making': ['ржХрзЛржиржЯрж╛ ржнрж╛рж▓рзЛ', 'ржХрзЛржиржЯрж┐ ржЙрждрзНрждржо'],
                'problem_solving': ['рж╕ржорж╕рзНржпрж╛', 'ржЕрж╕рзБржмрж┐ржзрж╛', 'ржХрж╖рзНржЯ']
            }
        }
    
    def _load_phonetic_variants(self) -> Dict:
        """ЁЯФК Load phonetic variants and common misspellings"""
        return {
            'phonetic_mappings': {
                'ржПржХрж╛ржЙржирзНржЯ': ['ржЕрзНржпрж╛ржХрж╛ржЙржирзНржЯ', 'ржПржХрж╛ржЙржирзНржЯ', 'ржПржХрж╛ржЙржирзНржЯ'],
                'ржЗржирзНржЯрж╛рж░рзЗрж╕рзНржЯ': ['ржЗржирзНржЯрж╛рж░рж╕рзЗржЯ', 'ржЗржирзНржЯрж╛рж░рзЗрж╖рзНржЯ', 'ржЗржирзНржЯрзЗрж░рзЗрж╕рзНржЯ'],
                'ржЪрж╛рж░рзНржЬ': ['ржЪрж╛рж░рзНржЬ', 'ржЪрж╛рж░рзНржЬ', 'ржЪрж╛рж░рзНржЬ'],
                'рж╕рж╛рж░рзНржнрж┐рж╕': ['рж╕рзЗржмрж╛', 'рж╕рж╛рж░рзНржнрж┐рж╕', 'рж╕рзЗржмрж┐рж╕'],
                'ржмрзНржпрж╛ржВржХ': ['ржмрзНржпрж╛ржЩрзНржХ', 'ржмрзНржпрж╛ржВржХ', 'ржмрж╛ржВржХ']
            },
            
            'common_typos': {
                'ржПржХрж╛ржЙржирзНржЯ': ['ржПржХрж╛ржКржирзНржЯ', 'ржПржХрж╛ржЙржирзНржд', 'ржПржХрж╛ржЙржиржЯ'],
                'рж╕рзБржмрж┐ржзрж╛': ['рж╕рзБржнрж┐ржзрж╛', 'рж╕рзБржмрж┐ржжрж╛', 'рж╕рзБржмрж┐ржз'],
                'ржЪрж╛рж░рзНржЬ': ['ржЪрж╛рж░рзНржп', 'ржЪрж╛рж░рзНржЬ', 'ржЪрж╛рж░рзНржЬ']
            }
        }
    
    def analyze_query(self, query: str) -> Dict:
        """ЁЯза Comprehensive Bengali query analysis"""
        analysis = {
            'original': query,
            'morphology': self._analyze_morphology(query),
            'semantics': self._analyze_semantics(query),
            'context': self._analyze_context(query),
            'enhanced_query': self._enhance_query(query),
            'confidence_boosts': self._calculate_boosts(query)
        }
        return analysis
    
    def _analyze_morphology(self, query: str) -> Dict:
        """ЁЯФд Morphological analysis"""
        analysis = {
            'question_type': None,
            'has_possessive': False,
            'has_verb_inflection': False,
            'politeness_level': 'neutral'
        }
        
        # Question type detection
        for qword in self.morphological_rules['question_words']:
            if qword in query:
                if qword in ['ржХржд', 'ржХрзЗржоржи']:
                    analysis['question_type'] = 'quantity_quality'
                elif qword in ['ржХрж┐', 'ржХрзА']:
                    analysis['question_type'] = 'yes_no_what'
                elif qword in ['ржХрж┐ржнрж╛ржмрзЗ', 'ржХрзЗржи']:
                    analysis['question_type'] = 'method_reason'
                break
        
        # Possessive markers
        analysis['has_possessive'] = any(marker in query for marker in self.morphological_rules['possessive_markers'])
        
        # Verb inflections
        analysis['has_verb_inflection'] = any(verb in query for verb in self.morphological_rules['verb_inflections'])
        
        # Politeness level
        if any(formal in query for formal in ['ржЖржкржирж┐', 'ржЖржкржирж╛рж░', 'ржЖржкржирж╛ржжрзЗрж░']):
            analysis['politeness_level'] = 'formal'
        elif any(informal in query for informal in ['рждрзБржорж┐', 'рждрзЛржорж╛рж░']):
            analysis['politeness_level'] = 'informal'
        
        return analysis
    
    def _analyze_semantics(self, query: str) -> Dict:
        """ЁЯОп Semantic pattern matching"""
        semantic_matches = {
            'account_related': [],
            'interest_related': [],
            'charge_related': [],
            'benefit_related': [],
            'confidence_scores': {}
        }
        
        # Apply pattern matching for each category
        for category, patterns_data in self.semantic_mappings.items():
            category_key = category.replace('_terms', '_related')
            if category_key in semantic_matches:
                for pattern_info in patterns_data['patterns']:
                    if re.search(pattern_info['input'], query, re.IGNORECASE):
                        match_info = {
                            'pattern': pattern_info['input'],
                            'replacement': pattern_info['output'],
                            'context': pattern_info.get('context', 'general')
                        }
                        semantic_matches[category_key].append(match_info)
                
                # Calculate confidence for this category
                semantic_matches['confidence_scores'][category_key] = len(semantic_matches[category_key]) * 0.2
        
        return semantic_matches
    
    def _analyze_context(self, query: str) -> Dict:
        """ЁЯМЯ Cultural and domain context analysis"""
        context = {
            'banking_type': 'conventional',
            'domain_context': [],
            'formality': 'standard',
            'intent': 'information_seeking'
        }
        
        # Banking type detection
        if any(indicator in query.lower() for indicator in self.cultural_context['islamic_indicators']):
            context['banking_type'] = 'islamic'
        elif any(indicator in query.lower() for indicator in self.cultural_context['conventional_indicators']):
            context['banking_type'] = 'conventional'
        
        # Domain context
        if any(term in query.lower() for term in self.cultural_context['business_context']):
            context['domain_context'].append('business')
        if any(term in query.lower() for term in self.cultural_context['personal_context']):
            context['domain_context'].append('personal')
        
        # Formality
        if any(marker in query for marker in self.cultural_context['formality_markers']):
            context['formality'] = 'high'
        
        # Intent detection
        for intent, markers in self.cultural_context['question_intentions'].items():
            if any(marker in query for marker in markers):
                context['intent'] = intent
                break
        
        return context
    
    def _enhance_query(self, query: str) -> str:
        """ЁЯЪА Generate semantically enhanced query"""
        enhanced = query
        semantics = self._analyze_semantics(query)
        
        # Apply high-confidence semantic replacements
        for category, matches in semantics.items():
            if category == 'confidence_scores':
                continue
            
            for match in matches:
                if semantics['confidence_scores'].get(category, 0) > 0.3:
                    # Apply pattern replacement
                    enhanced = re.sub(match['pattern'], match['replacement'], enhanced, flags=re.IGNORECASE)
        
        return enhanced
    
    def _calculate_boosts(self, query: str) -> Dict:
        """ЁЯУК Calculate confidence boosts"""
        boosts = {
            'morphological': 0.0,
            'semantic': 0.0,
            'contextual': 0.0,
            'total': 0.0
        }
        
        morphology = self._analyze_morphology(query)
        semantics = self._analyze_semantics(query)
        context = self._analyze_context(query)
        
        # Morphological boost
        if morphology['question_type']:
            boosts['morphological'] += 0.1
        if morphology['has_possessive']:
            boosts['morphological'] += 0.05
        if morphology['politeness_level'] == 'formal':
            boosts['morphological'] += 0.05
        
        # Semantic boost
        total_semantic_confidence = sum(semantics['confidence_scores'].values())
        boosts['semantic'] = min(0.3, total_semantic_confidence)
        
        # Contextual boost
        if context['banking_type'] != 'conventional':
            boosts['contextual'] += 0.1
        if context['domain_context']:
            boosts['contextual'] += 0.05 * len(context['domain_context'])
        if context['formality'] == 'high':
            boosts['contextual'] += 0.05
        
        boosts['total'] = sum([boosts['morphological'], boosts['semantic'], boosts['contextual']])
        
        return boosts
    
    def optimize_for_search(self, query: str) -> Tuple[str, Dict]:
        """ЁЯФН Optimize query for search with metadata"""
        analysis = self.analyze_query(query)
        
        optimized_query = analysis['enhanced_query']
        metadata = {
            'confidence_boost': analysis['confidence_boosts']['total'],
            'semantic_confidence': analysis['confidence_boosts']['semantic'],
            'question_type': analysis['morphology']['question_type'],
            'banking_context': analysis['context']['banking_type'],
            'formality': analysis['context']['formality']
        }
        
        return optimized_query, metadata

def main():
    """ЁЯзк Test the semantic engine"""
    engine = BengaliSemanticEngine()
    
    test_queries = [
        "ржкрзЗрж░рзЛрж▓ ржПржХрж╛ржЙржирзНржЯрзЗрж░ рж╕рзБржмрж┐ржзрж╛рж╕ржорзВрж╣ ржХрзА ржХрзА?",
        "ржПржоржЯрж┐ржмрж┐ рж░рзЗржЧрзБрж▓рж╛рж░ ржЕрзНржпрж╛ржХрж╛ржЙржирзНржЯрзЗ ржХрж┐ ржЪрж╛рж░рзНржЬ ржЖржЫрзЗ?", 
        "ржмрзЗрждржирзЗрж░ ржПржХрж╛ржЙржирзНржЯрзЗ рж╕рзБржмрж┐ржзрж╛ ржХрж┐?",
        "ржЗржпрж╝рж╛ржХрж┐ржи ржПржХрж╛ржЙржирзНржЯрзЗрж░ ржЗржирзНржЯрж╛рж░рзЗрж╕рзНржЯ рж░рзЗржЯ ржХржд?",
        "ржорж╣рж┐рж▓рж╛ржжрзЗрж░ ржЬржирзНржп ржмрж┐рж╢рзЗрж╖ ржПржХрж╛ржЙржирзНржЯ ржЖржЫрзЗ ржХрж┐?"
    ]
    
    for query in test_queries:
        print(f"\nЁЯзк Query: {query}")
        optimized, metadata = engine.optimize_for_search(query)
        print(f"ЁЯЪА Optimized: {optimized}")
        print(f"ЁЯУК Confidence boost: {metadata['confidence_boost']:.3f}")
        print(f"тЭУ Question type: {metadata['question_type']}")
        print(f"ЁЯПж Banking context: {metadata['banking_context']}")

if __name__ == "__main__":
    main() 